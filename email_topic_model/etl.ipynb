{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Name: ETL (Extract, Transform, Load)**\n",
    "\n",
    "**Overview:** Connects to gmail via api, extracts all email data, and formulates it into a structured pandas dataframe for downstream ML unsupervised learning\n",
    "                \n",
    "**Data Scientist:** Aaron Medina\n",
    "\n",
    "**GitHub:**\n",
    "\n",
    "**Creation Date:** 10/27/2022\n",
    "\n",
    "**Instance:** Local\n",
    "\n",
    "**References:** https://developers.google.com/gmail/api/quickstart/python\n",
    "\n",
    "**Script Change Notes:**\n",
    "\n",
    "x/x/xxxx: Aaron - Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import base64\n",
    "import logging\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from typing import List #Union, Any, List, Optional, cast\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "credentials_file = 'credentials.json'\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n",
    "BATCH_SIZE = 100 # Maximum number of requests per second\n",
    "pdf_output_path = 'data/pdf.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=1023023998484-uojj8dlutmfnuh59r0d76bd08261nppa.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A49147%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.readonly&state=2ngUHuR5bxlO3tygTm8yhCui9Sp6Px&access_type=offline\n"
     ]
    }
   ],
   "source": [
    "# Initialize gmail API (Needs manual approval for now)\n",
    "flow = InstalledAppFlow.from_client_secrets_file(credentials_file, SCOPES)\n",
    "creds = flow.run_local_server(port=0)\n",
    "service = build('gmail', 'v1', credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to capture total number of email ids\n",
    "def list_messages_with_labels(service, user_id, label_ids=[]):\n",
    "    response = (service\n",
    "                .users()\n",
    "                .messages()\n",
    "                .list(userId=user_id,\n",
    "                      labelIds=label_ids).execute())\n",
    "    messages = list()\n",
    "    if 'messages' in response:\n",
    "        messages.extend(response['messages'])\n",
    "        while 'nextPageToken' in response:\n",
    "            page_token = response['nextPageToken']\n",
    "            response = (service\n",
    "                        .users()\n",
    "                        .messages()\n",
    "                        .list(userId=user_id,\n",
    "                              labelIds=label_ids,\n",
    "                              pageToken=page_token).execute())\n",
    "            messages.extend(response['messages'])\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Email(object):\n",
    "\n",
    "    \"\"\" Class that grabs all of the required tags and metadata from message API\"\"\"\n",
    "\n",
    "    def __init__(self, email: dict):\n",
    "        self._logger = logging.getLogger('Email')\n",
    "        self.id: str = email['id']\n",
    "        self.label_ids: List[str] = email.get('labelIds', None)\n",
    "        self.date: datetime = datetime.fromtimestamp(int(email['internalDate'])/1000)\n",
    "        self.size: int = email['sizeEstimate']\n",
    "        self.sender: str = None\n",
    "        self.to: str = None\n",
    "        self.subject: str = None\n",
    "            \n",
    "        if 'headers' in email['payload']:\n",
    "            self._parse_headers(email)\n",
    "        else:\n",
    "            self._logger.warning(f'Headers not found for email with id: {self.id}')\n",
    "            \n",
    "        self.__dict__ = self._as_dict()\n",
    "    \n",
    "    def _parse_headers(self, email: dict):\n",
    "        headers = email['payload']['headers']\n",
    "        for header in headers:\n",
    "            if header['name'] == 'From':\n",
    "                self.sender = header['value']\n",
    "            elif header['name'] == 'To':\n",
    "                self.to = header['value']\n",
    "            elif header['name'] == 'Subject':\n",
    "                self.subject = header['value']\n",
    "                \n",
    "    def _as_dict(self):\n",
    "        return {k: v for k, v in self.__dict__.items() if not k.startswith('_')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 2719 done\n",
      "100 out of 2719 done\n",
      "200 out of 2719 done\n",
      "300 out of 2719 done\n",
      "400 out of 2719 done\n",
      "500 out of 2719 done\n",
      "600 out of 2719 done\n",
      "700 out of 2719 done\n",
      "800 out of 2719 done\n",
      "900 out of 2719 done\n",
      "1000 out of 2719 done\n",
      "1100 out of 2719 done\n",
      "1200 out of 2719 done\n",
      "1300 out of 2719 done\n",
      "1400 out of 2719 done\n",
      "1500 out of 2719 done\n",
      "1600 out of 2719 done\n",
      "1700 out of 2719 done\n",
      "1800 out of 2719 done\n",
      "1900 out of 2719 done\n",
      "2000 out of 2719 done\n",
      "2100 out of 2719 done\n",
      "2200 out of 2719 done\n",
      "2300 out of 2719 done\n",
      "2400 out of 2719 done\n",
      "2500 out of 2719 done\n",
      "2600 out of 2719 done\n",
      "2700 out of 2719 done\n"
     ]
    }
   ],
   "source": [
    "# Pull emails in batches containing all tag data\n",
    "emails = list() # List of Dictionaries with the emails\n",
    "email_ids = list_messages_with_labels(service, 'me')\n",
    "\n",
    "def add_emails(request_id, response, exception):\n",
    "\n",
    "    \"\"\"Callback function that handles the result of each request\"\"\"\n",
    "\n",
    "    if exception is not None:\n",
    "        # Do something with the exception\n",
    "        raise ValueError(exception)\n",
    "    else:\n",
    "\n",
    "        # Convert the email to a dictionary using our Email class\n",
    "        emails.append(vars(Email(response)))\n",
    "\n",
    "batch = service.new_batch_http_request()\n",
    "\n",
    "for i, msg_id in enumerate(email_ids):\n",
    "\n",
    "    batch.add(service\n",
    "               .users()\n",
    "               .messages()\n",
    "               .get(userId = 'me', id = msg_id['id'])\n",
    "               , callback=add_emails)\n",
    "\n",
    "    if i % BATCH_SIZE == 0:\n",
    "        \n",
    "        batch.execute()\n",
    "        batch = service.new_batch_http_request()\n",
    "        print(f'{i} out of {len(email_ids)} done')\n",
    "        time.sleep(2)\n",
    "\n",
    "# Create a DataFrame from our list of emails\n",
    "tags_pdf = pd.DataFrame(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 2719 done\n",
      "100 out of 2719 done\n",
      "200 out of 2719 done\n",
      "300 out of 2719 done\n",
      "400 out of 2719 done\n",
      "500 out of 2719 done\n",
      "600 out of 2719 done\n",
      "700 out of 2719 done\n",
      "800 out of 2719 done\n",
      "900 out of 2719 done\n",
      "1000 out of 2719 done\n",
      "1100 out of 2719 done\n",
      "1200 out of 2719 done\n",
      "1300 out of 2719 done\n",
      "1400 out of 2719 done\n",
      "1500 out of 2719 done\n",
      "1600 out of 2719 done\n",
      "1700 out of 2719 done\n",
      "1800 out of 2719 done\n",
      "1900 out of 2719 done\n",
      "2000 out of 2719 done\n",
      "2100 out of 2719 done\n",
      "2200 out of 2719 done\n",
      "2300 out of 2719 done\n",
      "2400 out of 2719 done\n",
      "2500 out of 2719 done\n",
      "2600 out of 2719 done\n",
      "2700 out of 2719 done\n",
      "process complete: 0:15:02.732005\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\") \n",
    "\"\"\" Primary extraction loop process to pull all message bodies \"\"\"\n",
    "\n",
    "# Main variables\n",
    "message_id_list = tags_pdf['id']\n",
    "msg_pdf = pd.DataFrame()\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Loop through each message id to find the message\n",
    "for i, message_id in enumerate(message_id_list):\n",
    "\n",
    "    # Query main payload\n",
    "    msg = service.users().messages().get(userId=\"me\", id = message_id).execute()\n",
    "    payload = msg['payload']\n",
    "\n",
    "    # Conditions for different types of email messages (mimeType)\n",
    "    # There are many types of email formats, so need to encode/decode carefully\n",
    "    if payload['mimeType'] == \"text/html\":\n",
    "\n",
    "        # Convert byte code to html code\n",
    "        byte_code = payload[\"body\"][\"data\"]\n",
    "        msg_html = base64.urlsafe_b64decode(byte_code).decode(\"utf-8\")\n",
    "\n",
    "        # Error handling if tables or documents don't exist \n",
    "        try:\n",
    "            html_stage_pdf = pd.read_html(msg_html, index_col=0)\n",
    "            msg_body = html_stage_pdf[0].iloc[0].name\n",
    "        \n",
    "        except IndexError:\n",
    "            html_stage_pdf = pd.read_html(msg_html, header=0, index_col=0)[0]\n",
    "\n",
    "            # Special handling for html df output\n",
    "            try:\n",
    "                msg_body_list = html_stage_pdf['Unnamed: 1'].dropna().drop_duplicates().tolist()\n",
    "                msg_body = \" \".join(msg_body_list)\n",
    "            \n",
    "            # In case html df content is buried in the index section\n",
    "            except KeyError:\n",
    "                msg_body = html_stage_pdf.index.name\n",
    "\n",
    "        # Extract plain text from within specified html context\n",
    "        except ValueError:\n",
    "            html_regex = 'serif\">(.*?)</span>'\n",
    "            msg_body = str(re.findall(html_regex, msg_html))\n",
    "\n",
    "    # This section handles emails that are broken up into multiple sections\n",
    "    # We need to walk through these sections to extract all the text data\n",
    "    elif payload['mimeType'] in [\"multipart/alternative\", \"multipart/mixed\"]:\n",
    "\n",
    "        msg_body = \"\"\n",
    "        msg_body_part = \"\"\n",
    "        \n",
    "        # Step through each part of the payload, containing multiple pieces of text\n",
    "        for part in payload[\"parts\"]:\n",
    "\n",
    "            # Some parts contain blank fields, so skip\n",
    "            try:\n",
    "                byte_code = part[\"body\"][\"data\"]\n",
    "                msg_body_part = base64.urlsafe_b64decode(byte_code).decode(\"utf-8\")\n",
    "\n",
    "                # Condition that only BeautifulSoup can decode\n",
    "                if msg_body_part.find(\"DOCTYPE\") != -1:\n",
    "\n",
    "                    html_parsed = BeautifulSoup(msg_body_part, 'html.parser')\n",
    "                    msg_body_part = \"\"\n",
    "\n",
    "                    for para in html_parsed.find_all(\"p\"):\n",
    "                        msg_body_part = msg_body_part + \" \" + para.get_text()\n",
    "\n",
    "            # Skip sections that don't contain 'data' tag\n",
    "            except KeyError:\n",
    "                pass\n",
    "            \n",
    "            msg_body = msg_body + \" \" + msg_body_part\n",
    "\n",
    "            # Some message parts require additional html formatting to pandas\n",
    "            try:\n",
    "                msg_body = pd.read_html(msg_body, header=0, index_col=0)[0].columns[0]\n",
    "            except:\n",
    "                \n",
    "                pass\n",
    "\n",
    "    else:\n",
    "        print(payload['mimeType'])\n",
    "\n",
    "    # Format all data into a structured pandas df\n",
    "    stage_pdf = pd.DataFrame(columns = ['id', 'body'])\n",
    "    stage_pdf.loc[0, 'id'] = message_id\n",
    "    stage_pdf.loc[0, 'body'] = msg_body\n",
    "\n",
    "    msg_pdf = pd.concat([msg_pdf, stage_pdf])\n",
    "\n",
    "    # Provide status updates\n",
    "    if i % BATCH_SIZE == 0:\n",
    "        print(f'{i} out of {len(email_ids)} done')\n",
    "\n",
    "print(\"process complete:\", datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge tag df with message df\n",
    "pdf = tags_pdf.merge(msg_pdf, how = \"left\", on = ['id'])\n",
    "pdf['sub_body'] = pdf['subject'] + \" \" + pdf['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the file for downstream preprocessing\n",
    "pickle.dump(pdf, open(pdf_output_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label_ids</th>\n",
       "      <th>date</th>\n",
       "      <th>size</th>\n",
       "      <th>sender</th>\n",
       "      <th>to</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>sub_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18423c04ca1ade5c</td>\n",
       "      <td>[CATEGORY_PROMOTIONS, UNREAD, INBOX]</td>\n",
       "      <td>2022-10-29 12:38:35</td>\n",
       "      <td>220669</td>\n",
       "      <td>Best Buy Black Friday &lt;BestBuy@email.bestbuy.com&gt;</td>\n",
       "      <td>AARONJMEDINA12@gmail.com</td>\n",
       "      <td>You'll LOVE this - the offers don't stop</td>\n",
       "      <td></td>\n",
       "      <td>You'll LOVE this - the offers don't stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18420d6a61ff19e7</td>\n",
       "      <td>[CATEGORY_PROMOTIONS, UNREAD, INBOX]</td>\n",
       "      <td>2022-10-28 20:55:27</td>\n",
       "      <td>135637</td>\n",
       "      <td>The Exchange &lt;email@e.shopmyexchange.com&gt;</td>\n",
       "      <td>aaronjmedina12@gmail.com</td>\n",
       "      <td>Your Weekly Ad is Here: 12 Weeks of Scream-Wor...</td>\n",
       "      <td>The Exchange. Tax Free Shopping.\\r\\nView Emai...</td>\n",
       "      <td>Your Weekly Ad is Here: 12 Weeks of Scream-Wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184208a2e0b9f4b6</td>\n",
       "      <td>[CATEGORY_PROMOTIONS, UNREAD, INBOX]</td>\n",
       "      <td>2022-10-28 21:40:37</td>\n",
       "      <td>44129</td>\n",
       "      <td>\"Freddy's\" &lt;marketing@l.freddys.com&gt;</td>\n",
       "      <td>aaronjmedina12@gmail.com</td>\n",
       "      <td>Fry-teningly Delicious ðŸ‘»ðŸ˜‹</td>\n",
       "      <td>( http://url7889.l.freddys.com/ls/click?upn=-...</td>\n",
       "      <td>Fry-teningly Delicious ðŸ‘»ðŸ˜‹  ( http://url7889.l....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18420731aded8f8a</td>\n",
       "      <td>[CATEGORY_PROMOTIONS, UNREAD, INBOX]</td>\n",
       "      <td>2022-10-28 21:15:09</td>\n",
       "      <td>233275</td>\n",
       "      <td>Best Buy Black Friday &lt;BestBuy@email.bestbuy.com&gt;</td>\n",
       "      <td>AARONJMEDINA12@gmail.com</td>\n",
       "      <td>Your SALE update is HERE! There are so many of...</td>\n",
       "      <td></td>\n",
       "      <td>Your SALE update is HERE! There are so many of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184203652769a7fa</td>\n",
       "      <td>[SENT]</td>\n",
       "      <td>2022-10-28 20:09:01</td>\n",
       "      <td>8155</td>\n",
       "      <td>Aaron Medina &lt;aaronjmedina12@gmail.com&gt;</td>\n",
       "      <td>Stephen Lush from Charles River Laboratories I...</td>\n",
       "      <td>Re: REMOTE Sr Data Scientist Search-Help Lead ...</td>\n",
       "      <td>Hello Stephen,\\r\\n\\r\\nThank you for your inte...</td>\n",
       "      <td>Re: REMOTE Sr Data Scientist Search-Help Lead ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                             label_ids                date  \\\n",
       "0  18423c04ca1ade5c  [CATEGORY_PROMOTIONS, UNREAD, INBOX] 2022-10-29 12:38:35   \n",
       "1  18420d6a61ff19e7  [CATEGORY_PROMOTIONS, UNREAD, INBOX] 2022-10-28 20:55:27   \n",
       "2  184208a2e0b9f4b6  [CATEGORY_PROMOTIONS, UNREAD, INBOX] 2022-10-28 21:40:37   \n",
       "3  18420731aded8f8a  [CATEGORY_PROMOTIONS, UNREAD, INBOX] 2022-10-28 21:15:09   \n",
       "4  184203652769a7fa                                [SENT] 2022-10-28 20:09:01   \n",
       "\n",
       "     size                                             sender  \\\n",
       "0  220669  Best Buy Black Friday <BestBuy@email.bestbuy.com>   \n",
       "1  135637          The Exchange <email@e.shopmyexchange.com>   \n",
       "2   44129               \"Freddy's\" <marketing@l.freddys.com>   \n",
       "3  233275  Best Buy Black Friday <BestBuy@email.bestbuy.com>   \n",
       "4    8155            Aaron Medina <aaronjmedina12@gmail.com>   \n",
       "\n",
       "                                                  to  \\\n",
       "0                           AARONJMEDINA12@gmail.com   \n",
       "1                           aaronjmedina12@gmail.com   \n",
       "2                           aaronjmedina12@gmail.com   \n",
       "3                           AARONJMEDINA12@gmail.com   \n",
       "4  Stephen Lush from Charles River Laboratories I...   \n",
       "\n",
       "                                             subject  \\\n",
       "0           You'll LOVE this - the offers don't stop   \n",
       "1  Your Weekly Ad is Here: 12 Weeks of Scream-Wor...   \n",
       "2                          Fry-teningly Delicious ðŸ‘»ðŸ˜‹   \n",
       "3  Your SALE update is HERE! There are so many of...   \n",
       "4  Re: REMOTE Sr Data Scientist Search-Help Lead ...   \n",
       "\n",
       "                                                body  \\\n",
       "0                                                      \n",
       "1   The Exchange. Tax Free Shopping.\\r\\nView Emai...   \n",
       "2   ( http://url7889.l.freddys.com/ls/click?upn=-...   \n",
       "3                                                      \n",
       "4   Hello Stephen,\\r\\n\\r\\nThank you for your inte...   \n",
       "\n",
       "                                            sub_body  \n",
       "0         You'll LOVE this - the offers don't stop    \n",
       "1  Your Weekly Ad is Here: 12 Weeks of Scream-Wor...  \n",
       "2  Fry-teningly Delicious ðŸ‘»ðŸ˜‹  ( http://url7889.l....  \n",
       "3  Your SALE update is HERE! There are so many of...  \n",
       "4  Re: REMOTE Sr Data Scientist Search-Help Lead ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of the data output\n",
    "pdf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4cce46d6be9934fbd27f9ca0432556941ea5bdf741d4f4d64c6cd7f8dfa8fba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
